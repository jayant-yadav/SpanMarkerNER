{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing & Training with SpanMarker\n",
    "[SpanMarker](https://github.com/tomaarsen/SpanMarkerNER) is an accessible yet powerful Python module for training Named Entity Recognition models.\n",
    "\n",
    "In this short notebook, we'll have a look at how to initialize and train an NER model using SpanMarker. For a larger and more general tutorial on how to use SpanMarker, please have a look at the [Getting Started](getting_started.ipynb) notebook."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup\n",
    "First of all, the `span_marker` Python module needs to be installed. If we want to use [Weights and Biases](https://wandb.ai/) for logging, we can install `span_marker` using the `[wandb]` extra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install span_marker\n",
    "# %pip install span_marker[wandb]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the dataset\n",
    "For this example, we'll load the commonly used [CoNLL2003 dataset](https://huggingface.co/datasets/conll2003) from the Hugging Face hub using ðŸ¤— Datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
       "        num_rows: 14041\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
       "        num_rows: 3250\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
       "        num_rows: 3453\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"conll2003\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = dataset[\"train\"].features[\"ner_tags\"].feature.names\n",
    "labels"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SpanMarker accepts any dataset as long as it has `tokens` and `ner_tags` columns. The `ner_tags` can be annotated using the IOB, IOB2, BIOES or BILOU labeling scheme, but also regular unschemed labels. This CoNLL dataset uses the common IOB or IOB2 labeling scheme, with PER, ORG, LOC and MISC labels."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing a `SpanMarkerModel`\n",
    "A SpanMarker model is initialized via [SpanMarkerModel.from_pretrained](https://tomaarsen.github.io/SpanMarkerNER/api/span_marker.modeling.html#span_marker.modeling.SpanMarkerModel.from_pretrained). This method will be familiar to those who know ðŸ¤— Transformers. It accepts either a path to a local model or the name of a model on the [Hugging Face Hub](https://huggingface.co/models).\n",
    "\n",
    "Importantly, the model can *either* be an encoder or an already trained and saved SpanMarker model. As we haven't trained anything yet, we will use an encoder. To learn how to load and use a saved SpanMarker model, please have a look at the [Loading & Inferencing](model_loading.ipynb) notebook.\n",
    "\n",
    "Reasonable options for encoders include BERT and RoBERTa, which means that the following are all good options:\n",
    "\n",
    "* [prajjwal1/bert-tiny](https://huggingface.co/prajjwal1/bert-tiny)\n",
    "* [prajjwal1/bert-mini](https://huggingface.co/prajjwal1/bert-mini)\n",
    "* [prajjwal1/bert-small](https://huggingface.co/prajjwal1/bert-small)\n",
    "* [prajjwal1/bert-medium](https://huggingface.co/prajjwal1/bert-medium)\n",
    "* [bert-base-cased](https://huggingface.co/bert-base-cased)\n",
    "* [bert-large-cased](https://huggingface.co/bert-large-cased)\n",
    "* [roberta-base](https://huggingface.co/roberta-base)\n",
    "* [roberta-large](https://huggingface.co/roberta-large)\n",
    "\n",
    "Not all encoders work though, they **must** allow for `position_ids` as an input argument, which disqualifies DistilBERT, T5, DistilRoBERTa, ALBERT & BART. Furthermore, using uncased models is generally not recommended, as the capitalisation can be very useful to find named entities.\n",
    "\n",
    "We'll use `\"roberta-base\"` for this notebook. If you're running this on Google Colab, be sure to set hardware accelerator to \"GPU\" in `Runtime` > `Change runtime type`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from span_marker import SpanMarkerModel\n",
    "\n",
    "model_name = \"roberta-base\"\n",
    "model = SpanMarkerModel.from_pretrained(\n",
    "    model_name,\n",
    "    labels=labels,\n",
    "    model_max_length=256,\n",
    "    entity_max_length=6,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For us, these warnings are expected, as we are initializing `BertModel` for a new task.\n",
    "\n",
    "Note that we provided [SpanMarkerModel.from_pretrained](https://tomaarsen.github.io/SpanMarkerNER/api/span_marker.modeling.html#span_marker.modeling.SpanMarkerModel.from_pretrained) with a list of our labels. This is required when training a new model. See [Configuring](model_configuration.ipynb) for more details and recommendations on configuration options."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "At this point, our model is already ready for training! We can import [TrainingArguments](https://huggingface.co/docs/transformers/main_classes/trainer#transformers.TrainingArguments) directly from ðŸ¤— Transformers as well as the SpanMarker `Trainer`. The `Trainer` is a subclass of the ðŸ¤— Transformers [Trainer](https://huggingface.co/docs/transformers/main_classes/trainer) that simplifies some tasks for you, but otherwise it works just like the regular `Trainer`.\n",
    "\n",
    "This next snippet shows some reasonable defaults. Feel free to adjust the batch size to a lower value if you experience out of memory exceptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"models/span-marker-roberta-base-conll03\",\n",
    "    learning_rate=1e-5,\n",
    "    gradient_accumulation_steps=2,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=1,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    save_strategy=\"steps\",\n",
    "    eval_steps=500,\n",
    "    push_to_hub=False,\n",
    "    logging_steps=50,\n",
    "    fp16=True,\n",
    "    warmup_ratio=0.1,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can create a SpanMarker `Trainer` in the same way that you would initialize a ðŸ¤— Transformers `Trainer`. We'll train on a subsection of the data to save us some time. Amazingly, this `Trainer` will automatically create logs using exactly the logging tools that you have installed. With other words, if you prefer logging with [Tensorboard](https://www.tensorflow.org/tensorboard), all that you have to do is install it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "This SpanMarker model will ignore 0.097877% of all annotated entities in the train dataset. This is caused by the SpanMarkerModel maximum entity length of 6 words.\n",
      "These are the frequencies of the missed entities due to maximum entity length out of 23499 total entities:\n",
      "- 18 missed entities with 7 words (0.076599%)\n",
      "- 2 missed entities with 8 words (0.008511%)\n",
      "- 3 missed entities with 10 words (0.012767%)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>wandb\\run-20230428_160736-klxbldeq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong>woven-plasma-757</strong> to Weights & Biases (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be3fbeb39544469eba6382d146d521fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1802 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9477, 'learning_rate': 2.6519337016574586e-06, 'epoch': 0.03}\n",
      "{'loss': 0.2025, 'learning_rate': 5.414364640883978e-06, 'epoch': 0.06}\n",
      "{'loss': 0.1407, 'learning_rate': 8.176795580110498e-06, 'epoch': 0.08}\n",
      "{'loss': 0.1291, 'learning_rate': 9.895126465144972e-06, 'epoch': 0.11}\n",
      "{'loss': 0.0973, 'learning_rate': 9.58667489204195e-06, 'epoch': 0.14}\n",
      "{'loss': 0.0737, 'learning_rate': 9.278223318938926e-06, 'epoch': 0.17}\n",
      "{'loss': 0.0639, 'learning_rate': 8.969771745835904e-06, 'epoch': 0.19}\n",
      "{'loss': 0.0539, 'learning_rate': 8.661320172732882e-06, 'epoch': 0.22}\n",
      "{'loss': 0.0481, 'learning_rate': 8.352868599629858e-06, 'epoch': 0.25}\n",
      "{'loss': 0.0489, 'learning_rate': 8.044417026526836e-06, 'epoch': 0.28}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "This SpanMarker model won't be able to predict 0.172563% of all annotated entities in the evaluation dataset. This is caused by the SpanMarkerModel maximum entity length of 6 words.\n",
      "These are the frequencies of the missed entities due to maximum entity length out of 3477 total entities:\n",
      "- 5 missed entities with 7 words (0.143802%)\n",
      "- 1 missed entities with 10 words (0.028760%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.03809420391917229, 'eval_overall_precision': 0.8559068219633943, 'eval_overall_recall': 0.7527070529704419, 'eval_overall_f1': 0.8009965742759265, 'eval_overall_accuracy': 0.9548683524504692, 'eval_runtime': 13.4517, 'eval_samples_per_second': 153.661, 'eval_steps_per_second': 38.434, 'epoch': 0.28}\n",
      "{'loss': 0.0379, 'learning_rate': 7.735965453423812e-06, 'epoch': 0.31}\n",
      "{'loss': 0.039, 'learning_rate': 7.42751388032079e-06, 'epoch': 0.33}\n",
      "{'loss': 0.0373, 'learning_rate': 7.119062307217768e-06, 'epoch': 0.36}\n",
      "{'loss': 0.0362, 'learning_rate': 6.810610734114744e-06, 'epoch': 0.39}\n",
      "{'loss': 0.0287, 'learning_rate': 6.502159161011722e-06, 'epoch': 0.42}\n",
      "{'loss': 0.0283, 'learning_rate': 6.193707587908698e-06, 'epoch': 0.44}\n",
      "{'loss': 0.0308, 'learning_rate': 5.885256014805676e-06, 'epoch': 0.47}\n",
      "{'loss': 0.0266, 'learning_rate': 5.576804441702654e-06, 'epoch': 0.5}\n",
      "{'loss': 0.0193, 'learning_rate': 5.26835286859963e-06, 'epoch': 0.53}\n",
      "{'loss': 0.0163, 'learning_rate': 4.959901295496608e-06, 'epoch': 0.55}\n",
      "{'eval_loss': 0.018327122554183006, 'eval_overall_precision': 0.9140995260663507, 'eval_overall_recall': 0.9031314018144572, 'eval_overall_f1': 0.9085823641984395, 'eval_overall_accuracy': 0.9804157977059437, 'eval_runtime': 13.537, 'eval_samples_per_second': 152.693, 'eval_steps_per_second': 38.192, 'epoch': 0.55}\n",
      "{'loss': 0.0249, 'learning_rate': 4.651449722393585e-06, 'epoch': 0.58}\n",
      "{'loss': 0.0225, 'learning_rate': 4.342998149290562e-06, 'epoch': 0.61}\n",
      "{'loss': 0.0215, 'learning_rate': 4.0345465761875395e-06, 'epoch': 0.64}\n",
      "{'loss': 0.0251, 'learning_rate': 3.726095003084516e-06, 'epoch': 0.67}\n",
      "{'loss': 0.0186, 'learning_rate': 3.417643429981493e-06, 'epoch': 0.69}\n",
      "{'loss': 0.0212, 'learning_rate': 3.10919185687847e-06, 'epoch': 0.72}\n",
      "{'loss': 0.0166, 'learning_rate': 2.800740283775448e-06, 'epoch': 0.75}\n",
      "{'loss': 0.0226, 'learning_rate': 2.492288710672425e-06, 'epoch': 0.78}\n",
      "{'loss': 0.0162, 'learning_rate': 2.183837137569402e-06, 'epoch': 0.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at ...\n",
      "Loading cached processed dataset at ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0178, 'learning_rate': 1.8753855644663791e-06, 'epoch': 0.83}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.013812492601573467, 'eval_overall_precision': 0.9375370041444642, 'eval_overall_recall': 0.9268364062042728, 'eval_overall_f1': 0.9321559970566594, 'eval_overall_accuracy': 0.9858902502606882, 'eval_runtime': 13.6173, 'eval_samples_per_second': 151.793, 'eval_steps_per_second': 37.967, 'epoch': 0.83}\n",
      "{'loss': 0.017, 'learning_rate': 1.566933991363356e-06, 'epoch': 0.86}\n",
      "{'loss': 0.0164, 'learning_rate': 1.2584824182603333e-06, 'epoch': 0.89}\n",
      "{'loss': 0.0202, 'learning_rate': 9.500308451573104e-07, 'epoch': 0.92}\n",
      "{'loss': 0.0203, 'learning_rate': 6.415792720542875e-07, 'epoch': 0.94}\n",
      "{'loss': 0.0188, 'learning_rate': 3.3312769895126467e-07, 'epoch': 0.97}\n",
      "{'loss': 0.0175, 'learning_rate': 2.4676125848241828e-08, 'epoch': 1.0}\n",
      "{'train_runtime': 326.1576, 'train_samples_per_second': 44.193, 'train_steps_per_second': 5.525, 'train_loss': 0.06725485075976323, 'epoch': 1.0}\n"
     ]
    }
   ],
   "source": [
    "from span_marker import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"validation\"].select(range(2000)),\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now the final step is to compute the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at ...\n",
      "Loading cached processed dataset at ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.01344103179872036,\n",
       " 'eval_overall_precision': 0.9364892678623934,\n",
       " 'eval_overall_recall': 0.9321041849575651,\n",
       " 'eval_overall_f1': 0.9342915811088296,\n",
       " 'eval_overall_accuracy': 0.9861183524504692,\n",
       " 'eval_runtime': 13.1532,\n",
       " 'eval_samples_per_second': 157.148,\n",
       " 'eval_steps_per_second': 39.306,\n",
       " 'epoch': 1.0}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = trainer.evaluate()\n",
    "metrics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, we should evaluate using the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test_loss': 0.027700792998075485,\n",
       " 'test_overall_precision': 0.9039692701664532,\n",
       " 'test_overall_recall': 0.9067889908256881,\n",
       " 'test_overall_f1': 0.9053769350554182,\n",
       " 'test_overall_accuracy': 0.9796867082332724,\n",
       " 'test_runtime': 22.7367,\n",
       " 'test_samples_per_second': 155.915,\n",
       " 'test_steps_per_second': 39.012,\n",
       " 'epoch': 1.0}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(dataset[\"test\"], metric_key_prefix=\"test\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once trained, we can save our new model locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\"models/span-marker-roberta-base-conll03/checkpoint-final\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or we can push it to the ðŸ¤— Hub like so. I've commented it away for now to prevent people from accidentally pushing models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.push_to_hub()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to use it again, we can just load it using the checkpoint or using the model name on the Hub. This is how it would be done using a local checkpoint. See the [Loading & Inferencing](model_loading.ipynb) notebook for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = SpanMarkerModel.from_pretrained(\"models/span-marker-roberta-base-conll03/checkpoint-final\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That was all! As simple as that. If we put it all together into a single script, it looks something like this:\n",
    "```python\n",
    "from datasets import load_dataset\n",
    "from span_marker import SpanMarkerModel, Trainer\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "dataset = load_dataset(\"conll2003\")\n",
    "labels = dataset[\"train\"].features[\"ner_tags\"].feature.names\n",
    "\n",
    "model_name = \"roberta-base\"\n",
    "model = SpanMarkerModel.from_pretrained(model_name, labels=labels, model_max_length=256)\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"models/span-marker-roberta-base-conll03\",\n",
    "    learning_rate=1e-5,\n",
    "    gradient_accumulation_steps=2,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=1,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    save_strategy=\"steps\",\n",
    "    eval_steps=500,\n",
    "    push_to_hub=False,\n",
    "    logging_steps=50,\n",
    "    warmup_ratio=0.1,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=dataset[\"train\"].select(range(8000)),\n",
    "    eval_dataset=dataset[\"validation\"].select(range(2000)),\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "trainer.save_model(\"models/span-marker-roberta-base-conll03/checkpoint-final\")\n",
    "trainer.push_to_hub()\n",
    "\n",
    "metrics = trainer.evaluate()\n",
    "print(metrics)\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With `wandb` initialized, you can enjoy their very useful training graphs straight in your browser. It ends up looking something like this.\n",
    "![image](https://user-images.githubusercontent.com/37621491/235172501-a3cdae91-faf0-42b7-ac60-e6738b78e67e.png)\n",
    "![image](https://user-images.githubusercontent.com/37621491/235172726-795ded55-4b1c-40fa-ab91-476762f7dd57.png)\n",
    "\n",
    "Furthermore, you can use the `wandb` hyperparameter search functionality using the tutorial from the Hugging Face documentation [here](https://huggingface.co/docs/transformers/hpo_train). This transfers very well to the SpanMarker `Trainer`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "span-marker-ner",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c231fc6d0de0df4a232423539031d78e3a72f0f8d848d7b948e520fe3bfbe8ca"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
